{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2KemOj5D7MZo"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "as0GwV3B7Yp_"
   },
   "source": [
    "# Project 1 - Chicago, IL, Bikeshare Network Analysis  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vJllipjJulu3"
   },
   "source": [
    "The bike-sharing project analyzes the city's like-sharing program using network analysis. It uses data on rides, stations, and user profiles to optimize transportation efficiency and study user behaviors. By applying graph theory and clustering algorithms, the project aims to provide insights for urban planners, contributing to more efficient and eco-friendly commuting options."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fROUXigQsKAE"
   },
   "source": [
    "Analysis Questions:\n",
    "\n",
    "•\tWhat is the overall topology of the bike-sharing network, and how are stations interconnected?\n",
    "\n",
    "•\tWhat patterns exist in user behavior, and how do they vary between member and casual users?\n",
    "\n",
    "•\tHow do ride patterns differ between am and pm?\n",
    "\n",
    "•\tWhat are the most common starting and ending points for different user groups?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dahvg-uMvK1K"
   },
   "source": [
    "The dataset was gotten from Kaggle.comThe dataset contains data from the company that operates bike sharing services in Chicago city. The data contains 13 different datasets for each month for the year 2021. Each dataset contains 13 columns 49623 to 822411 rows each. Following are the columns in the dataset and what they represent:\n",
    "\n",
    "\n",
    "1.  Types of Data (Graph, Node, Edge Attributes)\n",
    "\n",
    "Attributes\n",
    "\n",
    "* ride_id : the unique id to refer to each trip\n",
    "\n",
    "* rideable_type : the type of the bike used for the trip\n",
    "\n",
    "* started_at : date-time for when the trip started\n",
    "\n",
    "* ended_at : date-time for when the trip ended\n",
    "\n",
    "* start_station_name : name of the station from where the trip started\n",
    "\n",
    "* start_station_id : unique id of the station from where the trip started\n",
    "\n",
    "* end_station_name : name of the station where the trip ended\n",
    "\n",
    "* end_station_id : unique id of the station where the trip ended\n",
    "\n",
    "* start_lat : latitude of the start station\n",
    "\n",
    "* start_lng : longitude of the start station\n",
    "\n",
    "* end_lat : latitude of the end station\n",
    "\n",
    "* end_lng : longitude of the end station\n",
    "\n",
    "* member_casual : member denotes the users who have subscribed to annual membership, and casual denotes the users who haven't\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tgx7gSdl6vHK"
   },
   "outputs": [],
   "source": [
    "#Load libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "from matplotlib.pyplot import figure\n",
    "import matplotlib.pyplot as plt\n",
    "from prettytable import PrettyTable\n",
    "#!pip install python-louvain matplotlib\n",
    "from community import community_louvain\n",
    "from itertools import combinations\n",
    "import folium #used to visualize interactive map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3jJ8_POMG9Ls"
   },
   "source": [
    "## Loading the Dataset  \n",
    "  \n",
    "The Bikeshare dataset was found to be too large to load into a GitHub repository. As a result, AWS S3 service was used as an alternative storage solution. In simple terms, the csv file was loaded into a bucket and given public read access. This allows the dataset to be read directly into a notebook with via a URL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F_C3yzJh7nw5"
   },
   "outputs": [],
   "source": [
    "#Loading csv file into notebook\n",
    "url = 'https://data620bucket.s3.us-east-2.amazonaws.com/202107-divvy-tripdata.csv'\n",
    "df = pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 167
    },
    "id": "ByE6DcPEKgXi",
    "outputId": "ab2090d2-c2b0-4535-b9d4-b84dc78f3ac8"
   },
   "outputs": [],
   "source": [
    "#Calculate Ride Duration and exclude rides under 2 mins\n",
    "# Ensure the columns are in datetime format\n",
    "df['started_at'] = pd.to_datetime(df['started_at'])\n",
    "df['ended_at'] = pd.to_datetime(df['ended_at'])\n",
    "df['ride_duration_minutes'] = (df['ended_at'] - df['started_at']).dt.total_seconds() / 60 #Create col for duration\n",
    "df = df.query('ride_duration_minutes >= 2') #filter to rides with duration over 2mins\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aNyM3rvlIoDM"
   },
   "source": [
    "## Converting the Dataframe Into a Networkx Graph Object\n",
    "  \n",
    "For this particular dataset two different graphing approches can be taken. The first one is to use a MultiDiGraph object, which would allow all the individual edges (bike rides) to remain in the graph.\n",
    "  \n",
    "The second approach is to use a DiGraph object, which would only add two directional edges between nodes. However, each directional edge will have aggregate data in its attributes to avoid the loss of valuable network information. For example, an edge between station 'X' and station 'Y' can have 400 rides - this means the edge would have a ride_count attribute equal to 400. Other metrics such as average ride duration in minutes can be calculated and included.\n",
    "\n",
    "Due to the limitations in computation capabalities and the large size of the dataset, we will opt for the DiGraph option."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x-_PnvuZIe_G"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PipwDTCySRSm"
   },
   "source": [
    "### Creating Graph Object - Adding Nodes & Edges\n",
    "The nodes represent unique bike stations, whereas the edges represent a trip between bike stations. It should be noted that some trips depart and arrive at the same station implying that there are self-loops in the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mvVWkg227g6k",
    "outputId": "6289596a-8e18-45e4-f1fe-d798d9075594"
   },
   "outputs": [],
   "source": [
    "# Initialize an empty DiGraph\n",
    "G = nx.DiGraph()\n",
    "\n",
    "# Add nodes with metadata from 'start_station_id' and 'start_station_name'\n",
    "for _, row in df.iterrows():\n",
    "    G.add_node(row['start_station_id'], name=row['start_station_name'])\n",
    "    G.add_node(row['end_station_id'], name=row['end_station_name'])\n",
    "\n",
    "print(len(G.nodes()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bnrbcLx8ymA2"
   },
   "source": [
    "### Adding Additonal Attributes to Nodes  \n",
    "\n",
    "The station coordinates were added to each node. This will help with marking each station on a geographical map. In addition, the count of self-loops have been added to each station. Furthermore, the edges were collapsed to count of rides and other aggregated data that may be useful for the network analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lx1ep6yLysF6",
    "outputId": "73500c2a-8206-4afc-8116-e44f3cbcfa49"
   },
   "outputs": [],
   "source": [
    "# Group by 'Category' and get the first entry of each group\n",
    "#gather start station info\n",
    "station_coord_df1 = df.groupby('start_station_id').first().filter(['start_station_id', 'start_lat', 'start_lng']).reset_index().rename(columns={'start_station_id': 'station',\n",
    "                                                                                                                                                'start_lat': 'lat',\n",
    "                                                                                                                                               'start_lng': 'lng'})\n",
    "#gather end station info\n",
    "station_coord_df2 = df.groupby('end_station_id').first().filter(['end_station_id', 'end_lat', 'end_lng']).reset_index().rename(columns={'end_station_id': 'station',\n",
    "                                                                                                                                                'end_lat': 'lat',\n",
    "                                                                                                                                               'end_lng': 'lng'})\n",
    "#Combine both dfs\n",
    "combined_df = pd.concat([station_coord_df1, station_coord_df2],\n",
    "                        #ignore_index=True,\n",
    "                       axis=0).drop_duplicates(subset='station').set_index('station')\n",
    "#print(combined_df.head(2))\n",
    "\n",
    "#Convert to dict\n",
    "pos = combined_df.apply(lambda row: (row['lat'], row['lng']), axis=1).to_dict()\n",
    "#print(pos)\n",
    "#print(str(list(pos.keys())[0]) + \" : \" + str(list(pos.values())[0]))\n",
    "nx.set_node_attributes(G, pos, 'coord') #Set coord attribute to graph\n",
    "\n",
    "\n",
    "\n",
    "#Get number of selfloops for each station and add as an attribute to each station\n",
    "self_loop_agg_df = df.query('start_station_id == end_station_id').groupby(['start_station_id', 'end_station_id']).agg(total_rides=('ride_id', 'count')).reset_index().drop(['start_station_id'], axis=1).rename(columns={'end_station_id': 'station'}).set_index('station')\n",
    "print(self_loop_agg_df.head(2))\n",
    "\n",
    "#Convert to dict\n",
    "self_loops_dict = self_loop_agg_df.apply(lambda row: (row['total_rides']), axis=1).to_dict()\n",
    "#print(self_loops_dict)\n",
    "\n",
    "nx.set_node_attributes(G, self_loops_dict, 'self_loops')\n",
    "\n",
    "\n",
    "\n",
    "#Get number of total_rides inititiated for each station and add as weight each station\n",
    "total_ride_cnt_agg = df.groupby('start_station_id').agg(total_rides=('ride_id', 'count')).reset_index().rename(columns={'start_station_id': 'station'}).set_index('station')\n",
    "#total_ride_cnt_agg.head()\n",
    "\n",
    "#Convert to dict\n",
    "total_ride_cnt_agg_dict = total_ride_cnt_agg.apply(lambda row: (row['total_rides']), axis=1).to_dict()\n",
    "\n",
    "nx.set_node_attributes(G, total_ride_cnt_agg_dict, 'weight') #Set weight attribute to graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_SJOvkr08Vqt",
    "outputId": "29a6d4a2-f936-4b47-e1a0-f2fffee973e5"
   },
   "outputs": [],
   "source": [
    "#Check attributes for a node:\n",
    "for node in G.nodes(data=True):\n",
    "    print(node)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z7Lkbl9nOU_P"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 112
    },
    "id": "OsBp2Xf_TJIM",
    "outputId": "18f478b5-841d-45e7-81e4-60506e1ddc3f"
   },
   "outputs": [],
   "source": [
    "# Aggregate data for edge attributes\n",
    "edge_aggregates = df.drop(df[df.start_station_id == df.end_station_id].index).groupby(['start_station_id', 'end_station_id']).agg(\n",
    "    total_rides=('ride_id', 'count'),\n",
    "    average_ride_duration_minutes=('ride_duration_minutes', 'mean'),\n",
    "    casual=('member_casual', lambda x: (x == 'casual').sum()),\n",
    "    member=('member_casual', lambda x: (x == 'member').sum()),\n",
    "    classic_bike=('rideable_type', lambda x: (x == 'classic_bike').sum()),\n",
    "    docked_bike=('rideable_type', lambda x: (x == 'docked_bike').sum()),\n",
    "    electric_bike=('rideable_type', lambda x: (x == 'electric_bike').sum())\n",
    ").reset_index()\n",
    "\n",
    "edge_aggregates.head(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F-e4iwBNTroq"
   },
   "outputs": [],
   "source": [
    "# Adding edges with attributes from the pivoted data\n",
    "for _, row in edge_aggregates.iterrows():\n",
    "    G.add_edge(row['start_station_id'], row['end_station_id'],\n",
    "               weight = row['total_rides'],\n",
    "               avg_ride_duration_min = row['average_ride_duration_minutes'],\n",
    "               casual = row['casual'],\n",
    "               member = row['member'],\n",
    "               classic_bike = row['classic_bike'],\n",
    "               docked_bike = row['docked_bike'],\n",
    "               electric_bike = row['electric_bike'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RSkNrQcFTxo3",
    "outputId": "337e2715-72f3-46aa-8f4b-a9361475225a"
   },
   "outputs": [],
   "source": [
    "#check attributes for an edge:\n",
    "start_station_id = list(G.edges(data=True))[0][0]\n",
    "end_station_id = list(G.edges(data=True))[0][1]\n",
    "edge_metadata = G.get_edge_data(start_station_id, end_station_id)\n",
    "print(edge_metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eropub9HPhJ4"
   },
   "source": [
    "## Islands in the Net\n",
    "The 'Islands in the Net' methodology aims to zero in on the cores of a network. By using the weight of the edges it can identify which nodesare most important by trimming low values. In our particular network analysis, this may identify the most active commuting routes. 19 edges found to be the most active according to an edge weight of 242. This yielded 14 stations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Hrz2YhT1P4Tn"
   },
   "outputs": [],
   "source": [
    "#Initialize functions to trim and 'islandize' components\n",
    "def trim_edges(g, weight=1):\n",
    "    g2=nx.Graph()\n",
    "    for f, to, edata in g.edges(data=True):\n",
    "        #print(f, to, edata, \" \", type(edata), edata['weight'])\n",
    "        #print(edata)\n",
    "        if edata['weight'] > weight:\n",
    "            g2.add_edge(f,to,**edata)\n",
    "    return g2\n",
    "\n",
    "def island_method(g, iterations=5):\n",
    "    weights = [edata['weight'] for f,to,edata in g.edges(data=True)]\n",
    "    #print(weights)\n",
    "    mn= int(min(weights))\n",
    "    mx= int(max(weights))\n",
    "    step= int((mx-mn)/iterations)\n",
    "    return [[threshold,trim_edges(g,threshold)] for threshold in range(mn,mx,step)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pxwUKqnfQfbH",
    "outputId": "5789e047-60e7-4881-a54a-be6fa602c913"
   },
   "outputs": [],
   "source": [
    "#Get largest graph component\n",
    "Gcc = sorted(nx.connected_components(nx.Graph(G)), key=len, reverse=True)\n",
    "G0 = G.subgraph(Gcc[0])\n",
    "\n",
    "# Get Threshold level, Size of each Graph, and the Number of connected of components\n",
    "islands = island_method(G0)\n",
    "for i in islands:\n",
    "    print(\"Threshold - \", \"# Nodes -\", \"# Islands\")\n",
    "    print(i[0], len(i[1]), len([len(c) for c in nx.connected_components(i[1])]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2kdX_iEIQkqv",
    "outputId": "3d2a61db-3b6b-4a2e-98fa-ba598f042a5b"
   },
   "outputs": [],
   "source": [
    "list(islands[1][1].nodes())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CZUt0ihbT3W0"
   },
   "source": [
    "## Visualizing the Network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 836
    },
    "id": "oW2wWH8aT5JB",
    "outputId": "109b3d89-692c-4731-c475-e86d0080369b"
   },
   "outputs": [],
   "source": [
    "# # Draw the graph\n",
    "figure(figsize=(10, 8))\n",
    "pos = nx.spring_layout(G) # Define the layout for node positioning\n",
    "nx.draw(G, pos, with_labels=False, node_size=25, node_color='skyblue', font_size=10, font_color='black')\n",
    "# Display the graph\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "og49lASp7gnH"
   },
   "source": [
    "### Visualizing Bikesharing Network On a Geographical Map  \n",
    "Given that this is a transportation, it would be valueble to view the graph on geographical map. It would help identify areas which have the highest activity. It was found that these stations have higher activity because its the downtown city center. You'll find banks, business, and office through these streets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gJ1Fwp6t7eom"
   },
   "outputs": [],
   "source": [
    "#Create function to Plot network on Map\n",
    "def plot_network_map(G1, subgraph=None, custom_prefix=\"network\"):\n",
    "    #Initialize Folium Map\n",
    "    center_lat = 41.8781#G.nodes['15442']['coord'][0] #lat\n",
    "    center_lon = -87.6298#G.nodes['15442']['coord'][1] #long\n",
    "    m = folium.Map(location=[center_lat, center_lon], zoom_start=11)\n",
    "\n",
    "    #filter if a subgraph is provided\n",
    "    if subgraph is not None:\n",
    "        nodes_in_subgraph = set()\n",
    "        for edge in subgraph.edges():\n",
    "            nodes_in_subgraph.update(edge)\n",
    "            G = G1.subgraph(nodes_in_subgraph).copy()\n",
    "    else:\n",
    "        G= G1\n",
    "\n",
    "    #Plot Nodes\n",
    "    for node, data in G.nodes(data=True):\n",
    "        #print(len(data))\n",
    "        if len(data) ==1:\n",
    "            continue\n",
    "        folium.Circle(location=[data['coord'][0], data['coord'][1]],\n",
    "                      radius=100,\n",
    "                      fill_color=\"green\",\n",
    "                      fill_opacity=0.8,\n",
    "                      popup=f'Node {node}').add_to(m)\n",
    "\n",
    "\n",
    "    #Plot Edges\n",
    "    for edge in list(G.edges()):\n",
    "        point1 = list(G.nodes[edge[0]]['coord']) #start\n",
    "        point2 = list(G.nodes[edge[1]]['coord']) #end\n",
    "        folium.PolyLine(locations=[point1, point2],\n",
    "                        weight=0.2,\n",
    "                        color='blue',\n",
    "                        fill_opacity=0.3,).add_to(m)\n",
    "\n",
    "    file_name= f\"{custom_prefix}_graph.html\"\n",
    "    m.save(file_name)\n",
    "\n",
    "    return display(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l2sKF4VjGOcD"
   },
   "outputs": [],
   "source": [
    "#Plots whole original graph\n",
    "plot_network_map(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F5BCx48fSMh2"
   },
   "outputs": [],
   "source": [
    "#Plots edges with a weight of 242 and above\n",
    "plot_network_map(G0, islands[1][1], custom_prefix=\"important_components\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QvAMM5FEg-Na"
   },
   "source": [
    "## Graph Traversal Methods\n",
    "\n",
    "Graph traversal methods involve visiting or processing nodes and edges in a graph in a specific order. Here, I'll demonstrate two common graph traversal methods: Breadth-First Search (BFS) a method for exploring the vertex level by level and Depth-First Search (DFS) a method for exploring the vertex deeply before moving to the next level. An algorithm like DFS can be used to create a tree called a DFS tree, or we can detect cycles in a graph. BFS can be used to find the shortest path in a graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 839
    },
    "id": "IWIaxlgdhFoS",
    "outputId": "353ad1a3-e7ee-4c87-a4c1-ae2dc2f16652"
   },
   "outputs": [],
   "source": [
    "def visualize_graph(graph, title, edge_attr='total_rides'):\n",
    "    pos = nx.spring_layout(graph)\n",
    "\n",
    "    # Use total rides as edge labels if available\n",
    "    edge_labels = {(start, end): f\"{edge_attr.capitalize()}: {graph[start][end].get(edge_attr, 'N/A')}\" for start, end in graph.edges}\n",
    "\n",
    "    nx.draw_networkx_nodes(graph, pos, node_size=300, node_color='skyblue')\n",
    "    #nx.draw_networkx_labels(graph, pos, font_size=8)\n",
    "    nx.draw_networkx_edges(graph, pos, edge_color='gray', arrowsize=10)\n",
    "    nx.draw_networkx_edge_labels(graph, pos, edge_labels=edge_labels, font_size=8)\n",
    "\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "# Breadth-First Search (BFS)\n",
    "bfs_tree = nx.bfs_tree(G, source='13001')\n",
    "visualize_graph(bfs_tree, title='Breadth-First Search (BFS)')\n",
    "\n",
    "# Depth-First Search (DFS)\n",
    "dfs_tree = nx.dfs_tree(G, source='13001')\n",
    "visualize_graph(dfs_tree, title='Depth-First Search (DFS)')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qFcUW8drhpUF"
   },
   "source": [
    "## Network Analysis Techniques\n",
    "\n",
    "### Centrality Measures:\n",
    "Degree Centrality is a measure of the number of connections a node has in a network.\n",
    "\n",
    "Betweenness Centrality measures the extent to which a node lies on the shortest paths between other nodes in the network.\n",
    "\n",
    "Closeness Centrality assesses how close a node is to all other nodes in the network, emphasizing nodes that are closer to others.\n",
    "\n",
    "Eigenvector Centrality evaluates the influence of a node in the network by considering not only its connections but also the connections of its neighbors.\n",
    "\n",
    "This code calculates and prints the top 10 nodes by four different centrality measures in a network graph using NetworkX."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "usb0-RDNhxYz",
    "outputId": "3210c54d-34bd-4e29-89c1-14a9fc2f00ad"
   },
   "outputs": [],
   "source": [
    "# Calculate Degree Centrality\n",
    "degree_centrality = nx.degree_centrality(G)\n",
    "sorted_degree_centrality = sorted(degree_centrality.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Create a PrettyTable for Degree Centrality\n",
    "degree_table = PrettyTable()\n",
    "degree_table.field_names = [\"Node\", \"Degree Centrality\", \"Top/Bottom\"]\n",
    "\n",
    "# Populate the table with the top 5 and bottom 5 nodes\n",
    "for i, (node, centrality) in enumerate(sorted_degree_centrality[:5] + sorted_degree_centrality[-5:]):\n",
    "    degree_table.add_row([node, centrality, \"Top 5\" if i < 5 else \"Bottom 5\"])\n",
    "\n",
    "# Print the Degree Centrality table\n",
    "print(\"Top 5 and Bottom 5 nodes by Degree Centrality:\")\n",
    "print(degree_table)\n",
    "\n",
    "# Repeat the above steps for other centrality measures (Betweenness, Closeness, Eigenvector)\n",
    "\n",
    "# Calculate Betweenness Centrality\n",
    "betweenness_centrality = nx.betweenness_centrality(G)\n",
    "sorted_betweenness_centrality = sorted(betweenness_centrality.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Create a PrettyTable for Betweenness Centrality\n",
    "betweenness_table = PrettyTable()\n",
    "betweenness_table.field_names = [\"Node\", \"Betweenness Centrality\", \"Top/Bottom\"]\n",
    "\n",
    "# Populate the table with the top 5 and bottom 5 nodes\n",
    "for i, (node, centrality) in enumerate(sorted_betweenness_centrality[:5] + sorted_betweenness_centrality[-5:]):\n",
    "    betweenness_table.add_row([node, centrality, \"Top 5\" if i < 5 else \"Bottom 5\"])\n",
    "\n",
    "# Print the Betweenness Centrality table\n",
    "print(\"\\nTop 5 and Bottom 5 nodes by Betweenness Centrality:\")\n",
    "print(betweenness_table)\n",
    "\n",
    "# Repeat similar steps for Closeness and Eigenvector centrality\n",
    "\n",
    "# Calculate Closeness Centrality\n",
    "closeness_centrality = nx.closeness_centrality(G)\n",
    "sorted_closeness_centrality = sorted(closeness_centrality.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Create a PrettyTable for Closeness Centrality\n",
    "closeness_table = PrettyTable()\n",
    "closeness_table.field_names = [\"Node\", \"Closeness Centrality\", \"Top/Bottom\"]\n",
    "\n",
    "# Populate the table with the top 5 and bottom 5 nodes\n",
    "for i, (node, centrality) in enumerate(sorted_closeness_centrality[:5] + sorted_closeness_centrality[-5:]):\n",
    "    closeness_table.add_row([node, centrality, \"Top 5\" if i < 5 else \"Bottom 5\"])\n",
    "\n",
    "# Print the Closeness Centrality table\n",
    "print(\"\\nTop 5 and Bottom 5 nodes by Closeness Centrality:\")\n",
    "print(closeness_table)\n",
    "\n",
    "# Calculate Eigenvector Centrality\n",
    "eigenvector_centrality = nx.eigenvector_centrality(G)\n",
    "sorted_eigenvector_centrality = sorted(eigenvector_centrality.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Create a PrettyTable for Eigenvector Centrality\n",
    "eigenvector_table = PrettyTable()\n",
    "eigenvector_table.field_names = [\"Node\", \"Eigenvector Centrality\", \"Top/Bottom\"]\n",
    "\n",
    "# Populate the table with the top 5 and bottom 5 nodes\n",
    "for i, (node, centrality) in enumerate(sorted_eigenvector_centrality[:5] + sorted_eigenvector_centrality[-5:]):\n",
    "    eigenvector_table.add_row([node, centrality, \"Top 5\" if i < 5 else \"Bottom 5\"])\n",
    "\n",
    "# Print the Eigenvector Centrality table\n",
    "print(\"\\nTop 5 and Bottom 5 nodes by Eigenvector Centrality:\")\n",
    "print(eigenvector_table)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RadYvmo7qNCL"
   },
   "source": [
    "The Degree Centrality is calculated as the number of edges connected to a node divided by the total number of nodes (or nodes minus one in the case of an undirected graph).\n",
    "Nodes with high degree centrality are considered more central or influential in the network due to their numerous connections.\n",
    "\n",
    "Betweenness Centrality is computed by counting the number of shortest paths between all pairs of nodes that pass through a particular node and then normalizing.\n",
    "Nodes with high betweenness centrality act as bridges or mediators in the network, connecting different parts and facilitating information flow.\n",
    "\n",
    "Closeness Centrality is calculated as the reciprocal of the sum of the shortest path distances from a node to all other nodes.\n",
    "Nodes with high closeness centrality are well-connected and can quickly interact with other nodes, making them central in terms of communication and information exchange.\n",
    "\n",
    "Eigenvector centrality is based on the eigenvector of the adjacency matrix of the network.\n",
    "Nodes with high eigenvector centrality are connected to other nodes that themselves have high centrality, indicating a level of importance that goes beyond the sheer number of connections."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2k7LU_t6mxWp"
   },
   "source": [
    "## Visualizing Centrality Measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "6yKSq6OzsdiD",
    "outputId": "fba694d7-d283-4a95-d381-0fdbe1fe0c2e"
   },
   "outputs": [],
   "source": [
    "def visualize_top_nodes(graph, centrality_measure, top_n=5):\n",
    "    centrality_values = centrality_measure(graph)\n",
    "    sorted_centrality = sorted(centrality_values.items(), key=lambda x: x[1], reverse=True)\n",
    "    top_nodes = dict(sorted_centrality[:top_n])\n",
    "\n",
    "    pos = nx.spring_layout(graph)\n",
    "    node_labels = {node: f\"{node}\\nCentrality: {centrality:.4f}\" for node, centrality in top_nodes.items()}\n",
    "\n",
    "    nx.draw_networkx_nodes(graph, pos, nodelist=top_nodes.keys(), node_size=300, node_color='skyblue')\n",
    "    #nx.draw_networkx_labels(graph, pos, labels=node_labels, font_size=8)\n",
    "    nx.draw_networkx_edges(graph, pos, edge_color='gray', arrowsize=10)\n",
    "\n",
    "    plt.title(f'Top {top_n} Nodes by {centrality_measure.__name__}')\n",
    "    plt.show()\n",
    "\n",
    "# Visualize the top 5 nodes for each centrality measure\n",
    "visualize_top_nodes(G, nx.degree_centrality, top_n=5)\n",
    "visualize_top_nodes(G, nx.betweenness_centrality, top_n=5)\n",
    "visualize_top_nodes(G, nx.closeness_centrality, top_n=5)\n",
    "visualize_top_nodes(G, nx.eigenvector_centrality, top_n=5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E_ZrUU-uj715"
   },
   "source": [
    "### The Top 5 Nodes for Each Centrality Measure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wnMC86oNkF4U",
    "outputId": "ebeaf295-7ca4-4136-eb37-988d1708172f"
   },
   "outputs": [],
   "source": [
    "dgr=nx.degree_centrality(G)\n",
    "bet=nx.betweenness_centrality(G)\n",
    "clo=nx.closeness_centrality(G)\n",
    "eig=nx.eigenvector_centrality(G)\n",
    "centralities = pd.concat(\n",
    "    [pd.Series(c) for c in (dgr, bet, clo, eig)],\n",
    "    axis=1)\n",
    "\n",
    "centralities.columns = (\"Degree\", \"Betweenness\", \"Closeness\", \"Eigenvector\")\n",
    "\n",
    "# Sort top 5 nodes for each centrality measure in the DataFrame\n",
    "top_nodes = pd.DataFrame(index=range(1, 6))  # Index for top 5 nodes\n",
    "\n",
    "for column in centralities.columns:\n",
    "    top_nodes[column] = centralities.nlargest(5, column).index\n",
    "\n",
    "print(top_nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VPqC-h-LkHkE"
   },
   "source": [
    "These results help identify which nodes play important roles in the network based on different measures, such as how many connections they have (Degree), how central they are in connecting different parts of the network (Betweenness), how close they are to other nodes (Closeness), and their influence within the network (Eigenvector)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BKaczGDVkRq1"
   },
   "source": [
    "### Correlations Between Different Centrality Measures In This Network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zdQbFAXEka73",
    "outputId": "75ad5b7d-752f-4f5c-bf9b-b62d345fb2a8"
   },
   "outputs": [],
   "source": [
    "c_df = centralities.corr()\n",
    "ll_triangle = np.tri(c_df.shape[0], k=-1)\n",
    "c_df *=ll_triangle\n",
    "c_series = c_df.stack().sort_values()\n",
    "c_series.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gAH_JGBMkfmM"
   },
   "source": [
    "Closeness and Betweenness (0.356149): There is a moderate positive relationship between closeness centrality and betweenness centrality. As nodes become closer to others in the network, they tend to have higher betweenness centrality.\n",
    "\n",
    "Betweenness and Degree (0.389617): There is a moderate positive relationship between betweenness centrality and degree centrality. Nodes with higher betweenness centrality also tend to have higher degrees.\n",
    "\n",
    "Eigenvector and Closeness (0.752089): There is a strong positive relationship between eigenvector centrality and closeness centrality. Nodes with higher eigenvector centrality also tend to be closer to other nodes.\n",
    "\n",
    "Closeness and Degree (0.779082): There is a strong positive relationship between closeness centrality and degree centrality. Nodes that are close to others in the network also tend to have higher degrees.\n",
    "\n",
    "Eigenvector and Degree (0.993507): There is a very strong positive relationship between eigenvector centrality and degree centrality. Nodes with higher eigenvector centrality also tend to have much higher degrees.\n",
    "\n",
    "These values represent the correlations between different centrality measures in your network. A positive correlation indicates that as one centrality measure increases, the other tends to increase as well. The strength of the correlation is indicated by the numerical values: closer to 1 implies a stronger relationship."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A4h2C8tnvrLh"
   },
   "source": [
    "### Community Detection\n",
    "\n",
    "This is a technique used in network analysis to identify groups of nodes that are more densely connected internally than with the rest of the network. Two popular methods for community detection are Modularity-based Methods and the Louvain Method. The Girvan-Newman Algorithm is often used for hierarchical community detection.\n",
    "\n",
    "Modularity-based Methods based method is a that quantifies the quality of a partition of a network into communities. It compares the actual number of edges within communities to the expected number of edges in a random network. Optimal community structure is achieved by maximizing the modularity function. Higher modularity values indicate better community structures.\n",
    "\n",
    "Louvain Method is a greedy optimization algorithm that aims to maximize modularity. It iteratively optimizes the modularity by moving nodes between communities to find the best partition. It identifies a community structure that maximizes internal connectivity and minimizes external connectivity.\n",
    "\n",
    "Girvan-Newman Algorithm is based on the idea of edge betweenness. It identifies edges that, when removed, lead to the greatest increase in network connectivity. The algorithm iteratively removes edges with the highest betweenness until the community structure is revealed. The resulting dendrogram can be cut at different levels to identify communities at different scales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "xwRZBjs846F9",
    "outputId": "310f4506-7ce4-4941-b260-18caa40b7bdb"
   },
   "outputs": [],
   "source": [
    "# Convert the graph to an undirected graph for community detection\n",
    "G_undirected = G.to_undirected()\n",
    "\n",
    "# Apply the Louvain method to detect communities\n",
    "# partition = community.best_partition(G_undirected)\n",
    "comms = community_louvain.best_partition(G_undirected)\n",
    "\n",
    "# Visualize the communities\n",
    "pos = nx.spring_layout(G)\n",
    "cmap = plt.get_cmap('viridis')\n",
    "\n",
    "nx.draw_networkx_nodes(G, pos, node_size=300, cmap=cmap, node_color=list(comms.values()))\n",
    "nx.draw_networkx_edges(G, pos, alpha=0.5)\n",
    "plt.title('Community Detection using Modularity-based Methods (Louvain)')\n",
    "plt.show()\n",
    "\n",
    "# Print community assignments for each node\n",
    "for node, community_id in comms.items():\n",
    "    print(f\"Node {node} belongs to Community {community_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 675
    },
    "id": "ZTnCh8UAqTBC",
    "outputId": "9dad3c3d-43d4-4764-840c-c615ba918231"
   },
   "outputs": [],
   "source": [
    "pos = nx.spring_layout(G)\n",
    "cmap = plt.get_cmap('viridis')\n",
    "plt.figure(figsize=(12, 8))\n",
    "nx.draw_networkx_nodes(G, pos, node_size=300, cmap=cmap, node_color=list(comms.values()))\n",
    "nx.draw_networkx_edges(G, pos, alpha=0.5)\n",
    "plt.title('Community Detection using Modularity-based Methods (Louvain)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PQdBUFWE4XIG"
   },
   "source": [
    "### PageRank Algorithm\n",
    "Application for Ranking Nodes\n",
    "\n",
    "PageRank algorithm assigns a numerical weight to each node in a network graph. The purpose of PageRank is to measure the importance of a node based on its connections and the importance of nodes connected to it.\n",
    "\n",
    "Nodes with higher PageRank values are considered more important or central in the network. It implies that the node has more influential connections or is connected to other important nodes.\n",
    "\n",
    "Nodes with lower PageRank values are considered less important or central. They might have fewer or less influential connections.\n",
    "\n",
    "Here are the top 10 and lower 10 nodes based on their PageRank values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jrdHBHiT4i9F",
    "outputId": "7f7bd800-bc70-4a29-9be8-84cc4894f3f6"
   },
   "outputs": [],
   "source": [
    "pr = nx.pagerank(G)\n",
    "\n",
    "# Sort nodes by PageRank values in descending order\n",
    "sorted_pr = sorted(pr.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Print the top 5 nodes\n",
    "print(\"\\nTop 5 nodes by PageRank:\")\n",
    "for node, pagerank in sorted_pr[:5]:\n",
    "    print(f\"Node {node}: {pagerank}\")\n",
    "\n",
    "# Print the lower 5 nodes\n",
    "print(\"\\nLower 5 nodes by PageRank:\")\n",
    "for node, pagerank in sorted_pr[-5:]:\n",
    "    print(f\"Node {node}: {pagerank}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gJlC1OhsCBzA"
   },
   "source": [
    "### Link Prediction\n",
    "Common Neighbors\n",
    "\n",
    "Link prediction is a technique used in network analysis to predict the likelihood of a connection (link) between two nodes in a graph. One common approach for link prediction is based on common neighbors. The idea is that nodes that share common neighbors are more likely to form a link in the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5Cyi_clbCEA_",
    "outputId": "20823e9d-f1b2-4ed2-8e05-ce42a8541df4"
   },
   "outputs": [],
   "source": [
    "# Create a copy of the graph to work with\n",
    "G_copy = G.copy()\n",
    "\n",
    "# Identify potential links (missing edges) for prediction\n",
    "missing_edges = list(combinations(G_copy.nodes(), 2))\n",
    "\n",
    "# Remove existing edges from the list of potential links\n",
    "missing_edges = [edge for edge in missing_edges if not G_copy.has_edge(*edge)]\n",
    "\n",
    "# Calculate common neighbors for each potential link\n",
    "common_neighbors_predictions = []\n",
    "for edge in missing_edges:\n",
    "    common_neighbors = len(set(G_copy.neighbors(edge[0])) & set(G_copy.neighbors(edge[1])))\n",
    "    common_neighbors_predictions.append((edge, common_neighbors))\n",
    "\n",
    "# Sort predictions by common neighbors in descending order\n",
    "sorted_predictions = sorted(common_neighbors_predictions, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Print the top 5 link predictions based on common neighbors\n",
    "print(\"\\nTop 5 Link Predictions based on Common Neighbors:\")\n",
    "for prediction in sorted_predictions[:5]:\n",
    "    print(f\"Nodes {prediction[0]} with Common Neighbors: {prediction[1]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YCRUIY4JGLtv"
   },
   "source": [
    "### Routing Algorithms\n",
    "Shortest Path Algorithms are used in network analysis to find the most efficient path or route between two nodes in a graph.\n",
    "\n",
    "Dijkstra's algorithm is used to find the shortest path between a source node and all other nodes in a weighted graph.\n",
    "It works well for graphs with non-negative weights on edges.\n",
    "The algorithm maintains a set of visited nodes and calculates the shortest distance from the source node to each other node.\n",
    "It iteratively selects the node with the smallest tentative distance, adds it to the visited set, and updates the distances of its neighbors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KxuOWpFAGUP2",
    "outputId": "6ebf21bf-6d1d-462d-ee96-2391dc8021c5"
   },
   "outputs": [],
   "source": [
    "# Assuming source' is the source node\n",
    "source_node = '13001'\n",
    "\n",
    "# Calculate the shortest path lengths from the source node to all other nodes\n",
    "shortest_path_lengths = nx.single_source_dijkstra_path_length(G, source=source_node)\n",
    "\n",
    "# Get the top 10 nodes based on shortest path lengths\n",
    "top_5_nodes = sorted(shortest_path_lengths.items(), key=lambda x: x[1])[:5]\n",
    "\n",
    "# Print the result\n",
    "print(\"Top 5 nodes and their shortest path lengths:\")\n",
    "for node, length in top_5_nodes:\n",
    "    print(f\"Node {node}: Shortest Path Length = {length}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eQN9MU3yzoH6"
   },
   "source": [
    "Overall Topology of Bike-sharing Network:\n",
    "\n",
    "The bike-sharing network exhibits a diverse topology with stations interconnected through rides.\n",
    "Stations like 13022, 13300, and 13008 have high centrality, indicating they are well-connected hubs.\n",
    "\n",
    "Patterns in User Behavior:\n",
    "\n",
    "Degree Centrality identifies stations like LF-005 as crucial points, potentially serving as popular destinations.\n",
    "Betweenness Centrality highlights stations like 13008 and TA1308000009, suggesting they play a key role in connecting different parts of the network.\n",
    "Closeness Centrality showcases stations like 13022 and 13300 as central locations, emphasizing their accessibility.\n",
    "\n",
    "Common Starting and Ending Points for User Groups:\n",
    "\n",
    "Eigenvector Centrality identifies stations like 13022, 13042, and LF-005 as significant in terms of user influence.\n",
    "Stations with high Eigenvector Centrality may represent popular starting or ending points for different user groups.\n",
    "\n",
    "In summary, the provided centrality measures offer valuable insights into the network's structure and user behaviors, but additional temporal and user-specific analyses would provide more detailed answers to some of the questions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_1FUkpECD6S-"
   },
   "source": [
    "Reference: https://www.kaggle.com/datasets/lakshmi25npathi/bike-sharing-dataset"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
